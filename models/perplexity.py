from typing import Any
import torch
import re
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
import sys


class perplexity:
    def __init__(
        self, device="cpu", model="gpt2", threshold=80, separately=True
    ):
        """
        Initializes the Perplexity class with the specified parameters.

        Parameters:
        - device: str, default="cpu". Device to use for the model (e.g., "cpu" or "cuda").
        - model: str, default="gpt2". Pretrained model to use for tokenization and language modeling.
        - threshold: int, default=80. Threshold for the second perplexity range.
        - separately: bool, default=True. If True, evaluates perplexity separately for each line in the input text.
        """
        self.device = device
        self.tokenizer = GPT2TokenizerFast.from_pretrained(model)
        self.model = GPT2LMHeadModel.from_pretrained(model).to(device)
        self.max_length = self.model.config.n_positions
        self.threshold = threshold
        self.stride = 50
        self.method = separately

    def sentenceppl(self, sentence):
        """
        Computes perplexity for a given sentence.

        Parameters:
        - sentence: str. Input sentence for perplexity computation.

        Returns:
        - ppl: int. Perplexity value for the input sentence.
        """
        last_end = 0
        encodings = self.tokenizer(sentence, return_tensors="pt")
        len_sentence = encodings.input_ids.size(1)
        last_end = 0
        begin = 0
        nll_column = []
        nlls = []

        while last_end < len_sentence:
            end = min(begin + self.max_length, len_sentence)
            target_len = end - begin
            input_ids = encodings.input_ids[:, begin:end].to(self.device)
            target_ids = input_ids.clone()
            target_ids[:, -target_len] = -100
            with torch.no_grad():
                output = self.model(input_ids, labels=target_ids)
                nll_unit = output.loss * target_len
                nll_column.append(nll_unit)
            nlls.append(nll_column)
            begin = begin + self.stride
            last_end = end
        ppl = torch.exp(
            torch.stack([torch.Tensor(nll) for nll in nlls]).sum() / len_sentence
        )
        if torch.isnan(ppl):
            return ppl
        else:
            return int(ppl)

    def result(self, value):
        """
        Determines the result label based on the perplexity value.

        Parameters:
        - value: int. Perplexity value.

        Returns:
        - result: str. Result label description.
        - label: int. Result label (0 or 1).
        """
        if value < self.threshold:
            label = 0
            return "The paragraph is most likely generated by AI", label
        else:
            label = 1
            return "This paragraph is most likely artificial", label

    def __call__(self, text):
        """
        Evaluates the input text and prints the result label.

        Parameters:
        - text: str. Input text for evaluation.

        Returns:
        - label: int. Result label (0 or 1).
        """
        valid_text = re.findall("[a-zA-Z0-9]+", text)
        valid_length = sum([len(i) for i in valid_text])
        if valid_length < 100:
            print(
                f"The input text doesn't reach the requirement of 100 valid characters minimum "
            )
            sys.exit()

        if self.method:
            lines = re.split(r"(?<=[.?!][ \[\(])|(?<=\n)\s*", text)
            lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))
            offset = ""
            perlineppl = []
            for line in lines:
                if re.search("[a-zA-Z0-9]+", line) == None:
                    continue
                if len(offset) > 0:
                    line = offset + line
                    offset = ""
                # remove the new line pr space in the first sentence if exists
                if line[0] == "\n" or line[0] == " ":
                    line = line[1:]
                if line[-1] == "\n" or line[-1] == " ":
                    line = line[:-1]
                elif line[-1] == "[" or line[-1] == "(":
                    offset = line[-1]
                    line = line[:-1]
                ppl = self.sentenceppl(line)
                perlineppl.append(ppl)
            ppl = sum(perlineppl) / len(perlineppl)
            result, label = self.result(ppl)
            # print(result)
            # print(ppl)
            return label#,ppl
        else:
            ppl = self.sentenceppl(text)
            result, label = self.result(ppl)
            # print(result)
            # print(ppl)
            return label#,ppl
