from typing import Any
import torch, math, re
from transformers import (
    GPT2TokenizerFast,
    GPT2LMHeadModel,
    BertTokenizerFast,
    BertForMaskedLM,
)


class Detectorbydisc:
    def __init__(self, threshold, k=5, ratio=0.2, num_pert=5):
        torch.manual_seed(21)
        self.gpt = GPT2LMHeadModel.from_pretrained("gpt2")
        self.gptizer = GPT2TokenizerFast.from_pretrained("gpt2")
        self.bertinizer = BertTokenizerFast.from_pretrained("bert-base-uncased")
        self.bert = BertForMaskedLM.from_pretrained("bert-base-uncased")
        self.gptizer.pad_token = self.gptizer.eos_token
        self.bert.eval()
        self.k = k
        self.ratio = ratio
        self.num_pert = num_pert
        self.threshold = threshold
        self.eval = False

    def __call__(self, text: str):
        meandiscrepancy = self.get_discrepancy(text)
        if meandiscrepancy >= self.threshold:
            if self.eval:
                return 0
            else:
                print("the text is likely to be generated by GPT-2")
        else:
            if self.eval:
                return 1
            else:
                print("the text is not likely to be generated by GPT-2")

    def get_discrepancy(self, text: str, show_perturb=False, show_discrepancy=False):
        sentences = re.split(r"[.;!?]\s*", text)
        sentences = [sentence for sentence in sentences if sentence]
        meandiscrepancy = 0
        for sentence in sentences:
            meandiscrepancy += self.detect_sentence(sentence, show_perturb)
        meandiscrepancy /= len(sentences)
        if show_discrepancy:
            print(f"the discrepancy is {meandiscrepancy}")
        return meandiscrepancy

    @staticmethod
    def topk(logits, perturbed_mask, origin_tensor, k):
        top_k_indices = torch.topk(logits, k, dim=1).indices
        random_choices = torch.randint(0, k, (logits.size(0),))
        selected_indices = top_k_indices[torch.arange(logits.size(0)), random_choices]
        selected_indices[~perturbed_mask] = origin_tensor[~perturbed_mask]
        return selected_indices

    def detect_sentence(self, sentence: str, show_perturb=False):
        tuple_of_sentences, _ = self.perturb(sentence, self.ratio, self.num_pert)
        if show_perturb:
            for sentence in tuple_of_sentences:
                print(sentence)
        return self.get_discrepency(tuple_of_sentences)

    def perturb(self, sentence: str, ratio: float, num_purt: int) -> tuple:
        """perturb the text for num_purt times, return tuple of shape (num_purt+1,)"""
        origin_inputs = self.bertinizer(sentence, return_tensors="pt")
        length = origin_inputs.input_ids.size(dim=1)
        perturb_spots = math.ceil((length - 2) * ratio)
        perturbed_mask = torch.zeros(length)
        indices = torch.randperm(length - 3) + 2
        indices = indices[:perturb_spots]
        perturbed_mask[indices] = 1
        perturbed_mask = perturbed_mask.bool()
        sentences = [sentence]
        with torch.no_grad():
            outputs = self.bert(**origin_inputs)
            predictions = outputs.logits
        for _ in range(num_purt):
            temptext = self.bertinizer.convert_ids_to_tokens(
                self.topk(
                    predictions[0], perturbed_mask, origin_inputs.input_ids[0], self.k
                )
            )[1:-1]
            temptext = " ".join(temptext)
            temptext = re.sub(r"\s(?=[,.?:;'\"!)(])", "", temptext)
            temptext = re.sub(r"\s*-\s*", "-", temptext)
            temptext = re.sub(r"\s*—", "—", temptext)
            sentences.append(temptext)
        return tuple(sentences), perturbed_mask[1:-1]

    def get_discrepency(
        self,
        tuple_of_sentences: tuple,
    ) -> float:
        """get the difference between log(prob) of original text and expected that of purturbed texts"""
        origin_input = self.gptizer(tuple_of_sentences[0], return_tensors="pt")
        inputs = self.gptizer(
            tuple_of_sentences[1:], padding=True, truncation=True, return_tensors="pt"
        )
        with torch.no_grad():
            loss0 = self.gpt(**origin_input, labels=origin_input.input_ids).loss.item()
            meanloss = self.gpt(**inputs, labels=inputs.input_ids).loss.item()
        return loss0 - meanloss


if __name__ == "__main__":
    text = "Yesterday, a man named Jack said he saw an alien. He claimed that he had been out for a late-night walk in the remote woods, far from the city lights, when he stumbled upon an otherworldly encounter. Jack described the alien as having a humanoid shape, with shimmering, iridescent skin that seemed to change colors like a chameleon as it moved. Its eyes, he said, were large and almond-shaped, with a deep, piercing gaze that sent shivers down his spine."
    detector = Detectorbydisc()
    print(detector(text))
